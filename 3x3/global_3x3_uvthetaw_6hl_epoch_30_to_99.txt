Retraining the 3x3 global model with u,v,theta,w after ICML. Revisiting and checking why validation error was so high with the u,v,theta runs. Trainset = 2010+2012+2014 + all except may 2015. Validation set = May 2015.
File prefix: /scratch/users/ag4680/training_data/era5/nonlocal_3x3_inputfeatures_u_v_theta_w_uw_vw_era5_training_data_hourly_
Done
train batch size = 20
validation batch size = 20
Region: 1andes
total_time=2.2520294189453125
Input dim: 491, hidden dim: 1964, output dim: 244
CNN 1
model1 created. 
 --- model1 size: 75.15 MBs,
 --- Num params: 19.676 mil. 
CNN 1
model1 created. 
 --- model1 size: 75.15 MBs,
 --- Num params: 19.676 mil. 
Training...
Epoch 30, 1/70, training mseloss: 0.388212, testing mseloss: 0.374453
Epoch 31, 2/70, training mseloss: 0.392028, testing mseloss: 0.416744
Epoch 32, 3/70, training mseloss: 0.399990, testing mseloss: 0.378425
Epoch 33, 4/70, training mseloss: 0.391923, testing mseloss: 0.373962
Epoch 34, 5/70, training mseloss: 0.389756, testing mseloss: 0.374004
Epoch 35, 6/70, training mseloss: 0.388459, testing mseloss: 0.374758
Epoch 36, 7/70, training mseloss: 0.387509, testing mseloss: 0.375356
Epoch 37, 8/70, training mseloss: 0.386587, testing mseloss: 0.373037
Epoch 38, 9/70, training mseloss: 0.386677, testing mseloss: 0.369407
Epoch 39, 10/70, training mseloss: 0.385330, testing mseloss: 0.371812
Epoch 40, 11/70, training mseloss: 0.384800, testing mseloss: 0.373161
Epoch 41, 12/70, training mseloss: 0.385755, testing mseloss: 0.373557
Epoch 42, 13/70, training mseloss: 0.384232, testing mseloss: 0.370630
Epoch 43, 14/70, training mseloss: 0.385778, testing mseloss: 0.372360
Epoch 44, 15/70, training mseloss: 0.386245, testing mseloss: 0.375151
Epoch 45, 16/70, training mseloss: 0.384489, testing mseloss: 0.373644
Epoch 46, 17/70, training mseloss: 0.383524, testing mseloss: 0.371692
Epoch 47, 18/70, training mseloss: 0.382966, testing mseloss: 0.370792
Epoch 48, 19/70, training mseloss: 0.382527, testing mseloss: 0.370128
Epoch 49, 20/70, training mseloss: 0.382088, testing mseloss: 0.373838
Epoch 50, 21/70, training mseloss: 0.381784, testing mseloss: 0.372464
Epoch 51, 22/70, training mseloss: 0.381196, testing mseloss: 0.370807
Epoch 52, 23/70, training mseloss: 0.387178, testing mseloss: 0.379455
Epoch 53, 24/70, training mseloss: 0.385538, testing mseloss: 0.373893
Epoch 54, 25/70, training mseloss: 0.382276, testing mseloss: 0.374450
Epoch 55, 26/70, training mseloss: 0.380966, testing mseloss: 0.372170
Epoch 56, 27/70, training mseloss: 0.380368, testing mseloss: 0.371535
Epoch 57, 28/70, training mseloss: 0.460234, testing mseloss: 0.437410
Epoch 58, 29/70, training mseloss: 0.437747, testing mseloss: 0.409866
Epoch 59, 30/70, training mseloss: 0.414687, testing mseloss: 0.399735
Epoch 60, 31/70, training mseloss: 0.402631, testing mseloss: 0.388628
Epoch 61, 32/70, training mseloss: 0.395557, testing mseloss: 0.384322
Epoch 62, 33/70, training mseloss: 0.390930, testing mseloss: 0.379393
Epoch 63, 34/70, training mseloss: 0.387773, testing mseloss: 0.381878
Epoch 64, 35/70, training mseloss: 0.385802, testing mseloss: 0.381102
Epoch 65, 36/70, training mseloss: 0.385181, testing mseloss: 0.378418
Epoch 66, 37/70, training mseloss: 0.383400, testing mseloss: 0.377598
Epoch 67, 38/70, training mseloss: 0.382416, testing mseloss: 0.375308
Epoch 68, 39/70, training mseloss: 0.397687, testing mseloss: 0.384443
Epoch 69, 40/70, training mseloss: 0.390639, testing mseloss: 0.384897
Epoch 70, 41/70, training mseloss: 0.385634, testing mseloss: 0.379981
Epoch 71, 42/70, training mseloss: 0.382798, testing mseloss: 0.378919
Epoch 72, 43/70, training mseloss: 0.381344, testing mseloss: 0.378949
Epoch 73, 44/70, training mseloss: 0.380651, testing mseloss: 0.380353
Epoch 74, 45/70, training mseloss: 0.379635, testing mseloss: 0.377076
Epoch 75, 46/70, training mseloss: 0.379035, testing mseloss: 0.378472
Epoch 76, 47/70, training mseloss: 0.404466, testing mseloss: 0.428538
Epoch 77, 48/70, training mseloss: 0.411360, testing mseloss: 0.392895
Epoch 78, 49/70, training mseloss: 0.390948, testing mseloss: 0.388750
Epoch 79, 50/70, training mseloss: 0.386934, testing mseloss: 0.393530
Epoch 80, 51/70, training mseloss: 0.404491, testing mseloss: 0.387451
Epoch 81, 52/70, training mseloss: 0.386836, testing mseloss: 0.381069
Epoch 82, 53/70, training mseloss: 0.382892, testing mseloss: 0.382986
Epoch 83, 54/70, training mseloss: 0.389667, testing mseloss: 0.394483
Epoch 84, 55/70, training mseloss: 0.386023, testing mseloss: 0.381741
Epoch 85, 56/70, training mseloss: 0.379527, testing mseloss: 0.380393
Epoch 86, 57/70, training mseloss: 0.377783, testing mseloss: 0.377547
Epoch 87, 58/70, training mseloss: 0.377009, testing mseloss: 0.381719
Epoch 88, 59/70, training mseloss: 0.394438, testing mseloss: 0.532215
Epoch 89, 60/70, training mseloss: 0.481774, testing mseloss: 0.442583
Epoch 90, 61/70, training mseloss: 0.443108, testing mseloss: 0.424153
Epoch 91, 62/70, training mseloss: 0.427301, testing mseloss: 0.414095
Epoch 92, 63/70, training mseloss: 0.416140, testing mseloss: 0.410365
Epoch 93, 64/70, training mseloss: 0.407946, testing mseloss: 0.402736
Epoch 94, 65/70, training mseloss: 0.399843, testing mseloss: 0.397612
Epoch 95, 66/70, training mseloss: 0.392564, testing mseloss: 0.392133
Epoch 96, 67/70, training mseloss: 0.387076, testing mseloss: 0.390243
Epoch 97, 68/70, training mseloss: 0.389028, testing mseloss: 0.390176
Epoch 98, 69/70, training mseloss: 0.379796, testing mseloss: 0.381945
Epoch 99, 70/70, training mseloss: 0.379338, testing mseloss: 0.391247
Done
