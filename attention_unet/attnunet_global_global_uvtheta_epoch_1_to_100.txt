NGPUS = 1
Training the global horizontal and global vertical model with features uvtheta with min-max learning rates 0.001 to 0.009.
Training the global horizontal and global vertical model, with features uvtheta with min-max learning rates 0.001 to 0.009, and dropout=0. Starting from epoch 1. Training on years [2010 2012 2014] and testing on years [2015].
Defined input files
Model created. 
 --- model size: 144.61 MBs,
 --- Num params: 37.893 mil. 
Epoch 1, 1/100, training mseloss: 0.682510, testing mseloss: 0.822777
Epoch 2, 2/100, training mseloss: 0.641707, testing mseloss: 0.655393
Epoch 3, 3/100, training mseloss: 0.646794, testing mseloss: 0.641829
Epoch 4, 4/100, training mseloss: 0.617671, testing mseloss: 0.623369
Epoch 5, 5/100, training mseloss: 0.599739, testing mseloss: 0.615344
Epoch 6, 6/100, training mseloss: 0.582611, testing mseloss: 0.596820
Epoch 7, 7/100, training mseloss: 0.568063, testing mseloss: 0.577273
Epoch 8, 8/100, training mseloss: 0.557232, testing mseloss: 0.575305
Epoch 9, 9/100, training mseloss: 0.553631, testing mseloss: 0.605399
Epoch 10, 10/100, training mseloss: 0.538506, testing mseloss: 0.554454
Epoch 11, 11/100, training mseloss: 0.527747, testing mseloss: 0.559136
Epoch 12, 12/100, training mseloss: 0.518846, testing mseloss: 0.575340
Epoch 13, 13/100, training mseloss: 0.511063, testing mseloss: 0.551397
Epoch 14, 14/100, training mseloss: 0.506467, testing mseloss: 0.522662
Epoch 15, 15/100, training mseloss: 0.498081, testing mseloss: 0.530443
Epoch 16, 16/100, training mseloss: 0.492418, testing mseloss: 0.535924
Epoch 17, 17/100, training mseloss: 0.487212, testing mseloss: 0.508826
Epoch 18, 18/100, training mseloss: 0.482519, testing mseloss: 0.511319
Epoch 19, 19/100, training mseloss: 0.486726, testing mseloss: 0.539678
Epoch 20, 20/100, training mseloss: 0.505039, testing mseloss: 0.517586
Epoch 21, 21/100, training mseloss: 0.481388, testing mseloss: 0.500708
Epoch 22, 22/100, training mseloss: 0.475355, testing mseloss: 0.516098
Epoch 23, 23/100, training mseloss: 0.471792, testing mseloss: 0.512512
Epoch 24, 24/100, training mseloss: 0.468722, testing mseloss: 0.495406
Epoch 25, 25/100, training mseloss: 0.466308, testing mseloss: 0.494061
Epoch 26, 26/100, training mseloss: 0.463542, testing mseloss: 0.532474
Epoch 27, 27/100, training mseloss: 0.461402, testing mseloss: 0.498916
Epoch 28, 28/100, training mseloss: 0.459013, testing mseloss: 0.484802
Epoch 29, 29/100, training mseloss: 0.456645, testing mseloss: 0.562095
Epoch 30, 30/100, training mseloss: 0.454758, testing mseloss: 0.515410
Epoch 31, 31/100, training mseloss: 0.452874, testing mseloss: 0.479442
Epoch 32, 32/100, training mseloss: 0.451192, testing mseloss: 0.488939
Epoch 33, 33/100, training mseloss: 0.449508, testing mseloss: 0.531826
Epoch 34, 34/100, training mseloss: 0.448102, testing mseloss: 0.485583
Epoch 35, 35/100, training mseloss: 0.446829, testing mseloss: 0.476452
Epoch 36, 36/100, training mseloss: 0.445281, testing mseloss: 0.537491
Epoch 37, 37/100, training mseloss: 0.444296, testing mseloss: 0.485558
Epoch 38, 38/100, training mseloss: 0.443076, testing mseloss: 0.467604
Epoch 39, 39/100, training mseloss: 0.441968, testing mseloss: 0.487207
Epoch 40, 40/100, training mseloss: 0.440777, testing mseloss: 0.495593
Epoch 41, 41/100, training mseloss: 0.439842, testing mseloss: 0.472920
Epoch 42, 42/100, training mseloss: 0.439089, testing mseloss: 0.470794
Epoch 43, 43/100, training mseloss: 0.437644, testing mseloss: 0.493726
Epoch 44, 44/100, training mseloss: 0.436908, testing mseloss: 0.480337
Epoch 45, 45/100, training mseloss: 0.435955, testing mseloss: 0.466220
Epoch 46, 46/100, training mseloss: 0.434949, testing mseloss: 0.482492
Epoch 47, 47/100, training mseloss: 0.447194, testing mseloss: 0.508744
Epoch 48, 48/100, training mseloss: 0.440987, testing mseloss: 0.466990
Epoch 49, 49/100, training mseloss: 0.435740, testing mseloss: 0.470305
Epoch 50, 50/100, training mseloss: 0.433566, testing mseloss: 0.490295
Epoch 51, 51/100, training mseloss: 0.432590, testing mseloss: 0.476277
Epoch 52, 52/100, training mseloss: 0.431658, testing mseloss: 0.464162
Epoch 53, 53/100, training mseloss: 0.430708, testing mseloss: 0.479294
Epoch 54, 54/100, training mseloss: 0.430004, testing mseloss: 0.477168
Epoch 55, 55/100, training mseloss: 0.429356, testing mseloss: 0.460628
Epoch 56, 56/100, training mseloss: 0.428876, testing mseloss: 0.468312
Epoch 57, 57/100, training mseloss: 0.427842, testing mseloss: 0.499683
Epoch 58, 58/100, training mseloss: 0.427458, testing mseloss: 0.473541
Epoch 59, 59/100, training mseloss: 0.426933, testing mseloss: 0.462652
Epoch 60, 60/100, training mseloss: 0.426471, testing mseloss: 0.478937
Epoch 61, 61/100, training mseloss: 0.425761, testing mseloss: 0.476764
Epoch 62, 62/100, training mseloss: 0.425179, testing mseloss: 0.458565
Epoch 63, 63/100, training mseloss: 0.424761, testing mseloss: 0.470039
Epoch 64, 64/100, training mseloss: 0.423956, testing mseloss: 0.493493
Epoch 65, 65/100, training mseloss: 0.423608, testing mseloss: 0.468911
Epoch 66, 66/100, training mseloss: 0.423256, testing mseloss: 0.461480
Epoch 67, 67/100, training mseloss: 0.422407, testing mseloss: 0.473557
Epoch 68, 68/100, training mseloss: 0.422066, testing mseloss: 0.470731
Epoch 69, 69/100, training mseloss: 0.421577, testing mseloss: 0.455119
Epoch 70, 70/100, training mseloss: 0.421138, testing mseloss: 0.469140
Epoch 71, 71/100, training mseloss: 0.420460, testing mseloss: 0.481564
Epoch 72, 72/100, training mseloss: 0.420119, testing mseloss: 0.460417
Epoch 73, 73/100, training mseloss: 0.419856, testing mseloss: 0.457651
Epoch 74, 74/100, training mseloss: 0.419040, testing mseloss: 0.470465
Epoch 75, 75/100, training mseloss: 0.418777, testing mseloss: 0.468732
Epoch 76, 76/100, training mseloss: 0.418327, testing mseloss: 0.451443
Epoch 77, 77/100, training mseloss: 0.417873, testing mseloss: 0.467994
Epoch 78, 78/100, training mseloss: 0.417286, testing mseloss: 0.479073
Epoch 79, 79/100, training mseloss: 0.416927, testing mseloss: 0.455634
Epoch 80, 80/100, training mseloss: 0.416734, testing mseloss: 0.457096
Epoch 81, 81/100, training mseloss: 0.415961, testing mseloss: 0.472018
Epoch 82, 82/100, training mseloss: 0.415724, testing mseloss: 0.465038
Epoch 83, 83/100, training mseloss: 0.415426, testing mseloss: 0.452900
Epoch 84, 84/100, training mseloss: 0.414933, testing mseloss: 0.463954
Epoch 85, 85/100, training mseloss: 0.415324, testing mseloss: 0.468285
Epoch 86, 86/100, training mseloss: 0.414343, testing mseloss: 0.451654
Epoch 87, 87/100, training mseloss: 0.414046, testing mseloss: 0.459823
Epoch 88, 88/100, training mseloss: 0.413277, testing mseloss: 0.476030
Epoch 89, 89/100, training mseloss: 0.413102, testing mseloss: 0.463242
Epoch 90, 90/100, training mseloss: 0.412822, testing mseloss: 0.454285
Epoch 91, 91/100, training mseloss: 0.412331, testing mseloss: 0.463554
Epoch 92, 92/100, training mseloss: 0.411946, testing mseloss: 0.460754
Epoch 93, 93/100, training mseloss: 0.411830, testing mseloss: 0.449149
Epoch 94, 94/100, training mseloss: 0.411667, testing mseloss: 0.464475
Epoch 95, 95/100, training mseloss: 0.411055, testing mseloss: 0.531157
Epoch 96, 96/100, training mseloss: 0.412128, testing mseloss: 0.461724
Epoch 97, 97/100, training mseloss: 0.410817, testing mseloss: 0.457338
Epoch 98, 98/100, training mseloss: 0.410165, testing mseloss: 0.465549
Epoch 99, 99/100, training mseloss: 0.409810, testing mseloss: 0.457219
Epoch 100, 100/100, training mseloss: 0.409645, testing mseloss: 0.448226
Model training complete
