NGPUS = 1
Training the global horizontal and stratosphere_only vertical model with features uvthetaw with min-max learning rates 0.001 to 0.009.
Training the global horizontal and stratosphere_only vertical model, with features uvthetaw with min-max learning rates 0.001 to 0.009, and dropout=0. Starting from epoch 1. Training on years [2010 2012 2014] and testing on years [2015].
Defined input files
Model created. 
 --- model size: 144.30 MBs,
 --- Num params: 37.812 mil. 
Epoch 1, 1/100, training mseloss: 0.238613, testing mseloss: 0.253070
Epoch 2, 2/100, training mseloss: 0.212233, testing mseloss: 0.244051
Epoch 3, 3/100, training mseloss: 0.197911, testing mseloss: 0.200436
Epoch 4, 4/100, training mseloss: 0.185987, testing mseloss: 0.191404
Epoch 5, 5/100, training mseloss: 0.176992, testing mseloss: 0.193493
Epoch 6, 6/100, training mseloss: 0.170955, testing mseloss: 0.179000
Epoch 7, 7/100, training mseloss: 0.166472, testing mseloss: 0.166203
Epoch 8, 8/100, training mseloss: 0.161987, testing mseloss: 0.174931
Epoch 9, 9/100, training mseloss: 0.161371, testing mseloss: 0.191078
Epoch 10, 10/100, training mseloss: 0.157567, testing mseloss: 0.166844
Epoch 11, 11/100, training mseloss: 0.153550, testing mseloss: 0.162680
Epoch 12, 12/100, training mseloss: 0.150881, testing mseloss: 0.184573
Epoch 13, 13/100, training mseloss: 0.149830, testing mseloss: 0.156503
Epoch 14, 14/100, training mseloss: 0.146886, testing mseloss: 0.150221
Epoch 15, 15/100, training mseloss: 0.144798, testing mseloss: 0.172502
Epoch 16, 16/100, training mseloss: 0.143988, testing mseloss: 0.163213
Epoch 17, 17/100, training mseloss: 0.142606, testing mseloss: 0.147544
Epoch 18, 18/100, training mseloss: 0.141250, testing mseloss: 0.156134
Epoch 19, 19/100, training mseloss: 0.140621, testing mseloss: 0.179408
Epoch 20, 20/100, training mseloss: 0.143884, testing mseloss: 0.159617
Epoch 21, 21/100, training mseloss: 0.148798, testing mseloss: 0.168675
Epoch 22, 22/100, training mseloss: 0.220204, testing mseloss: 0.227612
Epoch 23, 23/100, training mseloss: 0.211593, testing mseloss: 0.219440
Epoch 24, 24/100, training mseloss: 0.204361, testing mseloss: 0.205606
Epoch 25, 25/100, training mseloss: 0.198725, testing mseloss: 0.201768
Epoch 26, 26/100, training mseloss: 0.193901, testing mseloss: 0.201621
Epoch 27, 27/100, training mseloss: 0.189889, testing mseloss: 0.194022
Epoch 28, 28/100, training mseloss: 0.185920, testing mseloss: 0.187694
Epoch 29, 29/100, training mseloss: 0.182562, testing mseloss: 0.195345
Epoch 30, 30/100, training mseloss: 0.179807, testing mseloss: 0.185209
Epoch 31, 31/100, training mseloss: 0.177044, testing mseloss: 0.177052
Epoch 32, 32/100, training mseloss: 0.174446, testing mseloss: 0.179855
Epoch 33, 33/100, training mseloss: 0.172126, testing mseloss: 0.184714
Epoch 34, 34/100, training mseloss: 0.169883, testing mseloss: 0.171924
Epoch 35, 35/100, training mseloss: 0.167400, testing mseloss: 0.168701
Epoch 36, 36/100, training mseloss: 0.165015, testing mseloss: 0.177400
Epoch 37, 37/100, training mseloss: 0.163036, testing mseloss: 0.168595
Epoch 38, 38/100, training mseloss: 0.160719, testing mseloss: 0.160117
Epoch 39, 39/100, training mseloss: 0.158575, testing mseloss: 0.163806
Epoch 40, 40/100, training mseloss: 0.156635, testing mseloss: 0.173725
Epoch 41, 41/100, training mseloss: 0.154728, testing mseloss: 0.157441
Epoch 42, 42/100, training mseloss: 0.152735, testing mseloss: 0.156500
Epoch 43, 43/100, training mseloss: 0.151045, testing mseloss: 0.171966
Epoch 44, 44/100, training mseloss: 0.149700, testing mseloss: 0.159034
Epoch 45, 45/100, training mseloss: 0.148085, testing mseloss: 0.150107
Epoch 46, 46/100, training mseloss: 0.146631, testing mseloss: 0.157827
Epoch 47, 47/100, training mseloss: 0.145524, testing mseloss: 0.168642
Epoch 48, 48/100, training mseloss: 0.144454, testing mseloss: 0.147224
Epoch 49, 49/100, training mseloss: 0.143126, testing mseloss: 0.149326
Epoch 50, 50/100, training mseloss: 0.142141, testing mseloss: 0.170112
Epoch 51, 51/100, training mseloss: 0.141352, testing mseloss: 0.148483
Epoch 52, 52/100, training mseloss: 0.140160, testing mseloss: 0.144495
Epoch 53, 53/100, training mseloss: 0.140446, testing mseloss: 0.156538
Epoch 54, 54/100, training mseloss: 0.138542, testing mseloss: 0.164530
Epoch 55, 55/100, training mseloss: 0.137620, testing mseloss: 0.140073
Epoch 56, 56/100, training mseloss: 0.139457, testing mseloss: 0.143467
Epoch 57, 57/100, training mseloss: 0.136509, testing mseloss: 0.167256
Epoch 58, 58/100, training mseloss: 0.135985, testing mseloss: 0.143706
Epoch 59, 59/100, training mseloss: 0.135875, testing mseloss: 0.140772
Epoch 60, 60/100, training mseloss: 0.134459, testing mseloss: 0.147108
Epoch 61, 61/100, training mseloss: 0.134055, testing mseloss: 0.157516
Epoch 62, 62/100, training mseloss: 0.133352, testing mseloss: 0.136833
Epoch 63, 63/100, training mseloss: 0.132567, testing mseloss: 0.146811
Epoch 64, 64/100, training mseloss: 0.132530, testing mseloss: 0.172258
Epoch 65, 65/100, training mseloss: 0.131937, testing mseloss: 0.393047
Epoch 66, 66/100, training mseloss: 0.132414, testing mseloss: 0.135905
Epoch 67, 67/100, training mseloss: 0.130770, testing mseloss: 0.187350
Epoch 68, 68/100, training mseloss: 0.131049, testing mseloss: 0.153894
Epoch 69, 69/100, training mseloss: 0.130059, testing mseloss: 0.138275
Epoch 70, 70/100, training mseloss: 0.130047, testing mseloss: 0.161364
Epoch 71, 71/100, training mseloss: 0.129682, testing mseloss: 0.158274
Epoch 72, 72/100, training mseloss: 0.129390, testing mseloss: 0.147456
Epoch 73, 73/100, training mseloss: 0.128973, testing mseloss: 0.134669
Epoch 74, 74/100, training mseloss: 0.128648, testing mseloss: 0.150093
Epoch 75, 75/100, training mseloss: 0.128301, testing mseloss: 0.139666
Epoch 76, 76/100, training mseloss: 0.128143, testing mseloss: 0.138928
Epoch 77, 77/100, training mseloss: 0.131764, testing mseloss: 0.152472
Epoch 78, 78/100, training mseloss: 0.127966, testing mseloss: 0.156009
Epoch 79, 79/100, training mseloss: 0.140948, testing mseloss: 0.283279
Epoch 80, 80/100, training mseloss: 0.178353, testing mseloss: 0.169589
Epoch 81, 81/100, training mseloss: 0.149792, testing mseloss: 0.157144
Epoch 82, 82/100, training mseloss: 0.141323, testing mseloss: 0.146971
Epoch 83, 83/100, training mseloss: 0.137009, testing mseloss: 0.138924
Epoch 84, 84/100, training mseloss: 0.134355, testing mseloss: 0.138983
Epoch 85, 85/100, training mseloss: 0.136577, testing mseloss: 0.166769
Epoch 86, 86/100, training mseloss: 0.131827, testing mseloss: 0.137988
Epoch 87, 87/100, training mseloss: 0.130511, testing mseloss: 0.151750
Epoch 88, 88/100, training mseloss: 0.129851, testing mseloss: 0.175598
Epoch 89, 89/100, training mseloss: 0.129208, testing mseloss: 0.139684
Epoch 90, 90/100, training mseloss: 0.128645, testing mseloss: 0.228960
Epoch 91, 91/100, training mseloss: 0.127987, testing mseloss: 0.166754
Epoch 92, 92/100, training mseloss: 0.127694, testing mseloss: 0.149570
Epoch 93, 93/100, training mseloss: 0.126928, testing mseloss: 0.135058
Epoch 94, 94/100, training mseloss: 0.126398, testing mseloss: 0.139848
Epoch 95, 95/100, training mseloss: 0.126085, testing mseloss: 0.156890
Epoch 96, 96/100, training mseloss: 0.128205, testing mseloss: 0.177659
Epoch 97, 97/100, training mseloss: 0.130233, testing mseloss: 0.148212
Epoch 98, 98/100, training mseloss: 0.125869, testing mseloss: 0.151629
Epoch 99, 99/100, training mseloss: 0.125705, testing mseloss: 0.148451
Epoch 100, 100/100, training mseloss: 0.125266, testing mseloss: 0.133549
Model training complete
