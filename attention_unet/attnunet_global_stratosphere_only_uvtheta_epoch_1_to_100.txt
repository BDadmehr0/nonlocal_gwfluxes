NGPUS = 1
Training the global horizontal and stratosphere_only vertical model with features uvtheta with min-max learning rates 0.001 to 0.009.
Training the global horizontal and stratosphere_only vertical model, with features uvtheta with min-max learning rates 0.001 to 0.009, and dropout=0. Starting from epoch 1. Training on years [2010 2012 2014] and testing on years [2015].
Defined input files
Model created. 
 --- model size: 144.17 MBs,
 --- Num params: 37.777 mil. 
Epoch 1, 1/100, training mseloss: 0.250473, testing mseloss: 0.253053
Epoch 2, 2/100, training mseloss: 0.239917, testing mseloss: 0.249329
Epoch 3, 3/100, training mseloss: 0.235798, testing mseloss: 0.243228
Epoch 4, 4/100, training mseloss: 0.232877, testing mseloss: 0.239636
Epoch 5, 5/100, training mseloss: 0.231034, testing mseloss: 0.242309
Epoch 6, 6/100, training mseloss: 0.236829, testing mseloss: 0.253069
Epoch 7, 7/100, training mseloss: 0.238299, testing mseloss: 0.239794
Epoch 8, 8/100, training mseloss: 0.233793, testing mseloss: 0.241094
Epoch 9, 9/100, training mseloss: 0.231827, testing mseloss: 0.241753
Epoch 10, 10/100, training mseloss: 0.231031, testing mseloss: 0.235083
Epoch 11, 11/100, training mseloss: 0.229421, testing mseloss: 0.234115
Epoch 12, 12/100, training mseloss: 0.228303, testing mseloss: 0.233578
Epoch 13, 13/100, training mseloss: 0.227540, testing mseloss: 0.231528
Epoch 14, 14/100, training mseloss: 0.225890, testing mseloss: 0.227088
Epoch 15, 15/100, training mseloss: 0.223085, testing mseloss: 0.225218
Epoch 16, 16/100, training mseloss: 0.217022, testing mseloss: 0.218677
Epoch 17, 17/100, training mseloss: 0.210977, testing mseloss: 0.212390
Epoch 18, 18/100, training mseloss: 0.206135, testing mseloss: 0.207814
Epoch 19, 19/100, training mseloss: 0.203097, testing mseloss: 0.211014
Epoch 20, 20/100, training mseloss: 0.202253, testing mseloss: 0.202348
Epoch 21, 21/100, training mseloss: 0.197894, testing mseloss: 0.196930
Epoch 22, 22/100, training mseloss: 0.195543, testing mseloss: 0.200008
Epoch 23, 23/100, training mseloss: 0.193596, testing mseloss: 0.199747
Epoch 24, 24/100, training mseloss: 0.191499, testing mseloss: 0.192729
Epoch 25, 25/100, training mseloss: 0.189125, testing mseloss: 0.196446
Epoch 26, 26/100, training mseloss: 0.187199, testing mseloss: 0.192718
Epoch 27, 27/100, training mseloss: 0.200771, testing mseloss: 0.195016
Epoch 28, 28/100, training mseloss: 0.189285, testing mseloss: 0.188407
Epoch 29, 29/100, training mseloss: 0.186740, testing mseloss: 0.196734
Epoch 30, 30/100, training mseloss: 0.187524, testing mseloss: 0.192699
Epoch 31, 31/100, training mseloss: 0.184544, testing mseloss: 0.184324
Epoch 32, 32/100, training mseloss: 0.182858, testing mseloss: 0.190159
Epoch 33, 33/100, training mseloss: 0.181770, testing mseloss: 0.190440
Epoch 34, 34/100, training mseloss: 0.180929, testing mseloss: 0.182840
Epoch 35, 35/100, training mseloss: 0.179724, testing mseloss: 0.183793
Epoch 36, 36/100, training mseloss: 0.179114, testing mseloss: 0.183954
Epoch 37, 37/100, training mseloss: 0.178245, testing mseloss: 0.182604
Epoch 38, 38/100, training mseloss: 0.177321, testing mseloss: 0.178444
Epoch 39, 39/100, training mseloss: 0.176608, testing mseloss: 0.182240
Epoch 40, 40/100, training mseloss: 0.175964, testing mseloss: 0.182302
Epoch 41, 41/100, training mseloss: 0.175341, testing mseloss: 0.177055
Epoch 42, 42/100, training mseloss: 0.220285, testing mseloss: 0.215814
Epoch 43, 43/100, training mseloss: 0.194272, testing mseloss: 0.204971
Epoch 44, 44/100, training mseloss: 0.188351, testing mseloss: 0.190425
Epoch 45, 45/100, training mseloss: 0.181538, testing mseloss: 0.182462
Epoch 46, 46/100, training mseloss: 0.179520, testing mseloss: 0.187796
Epoch 47, 47/100, training mseloss: 0.181732, testing mseloss: 0.194740
Epoch 48, 48/100, training mseloss: 0.178553, testing mseloss: 0.180088
Epoch 49, 49/100, training mseloss: 0.176480, testing mseloss: 0.186624
Epoch 50, 50/100, training mseloss: 0.175545, testing mseloss: 0.220270
Epoch 51, 51/100, training mseloss: 0.174852, testing mseloss: 0.189161
Epoch 52, 52/100, training mseloss: 0.173878, testing mseloss: 0.205843
Epoch 53, 53/100, training mseloss: 0.173218, testing mseloss: 0.181668
Epoch 54, 54/100, training mseloss: 0.172632, testing mseloss: 0.180072
Epoch 55, 55/100, training mseloss: 0.172038, testing mseloss: 0.175297
Epoch 56, 56/100, training mseloss: 0.171420, testing mseloss: 0.178673
Epoch 57, 57/100, training mseloss: 0.170796, testing mseloss: 0.189035
Epoch 58, 58/100, training mseloss: 0.170364, testing mseloss: 0.183306
Epoch 59, 59/100, training mseloss: 0.169699, testing mseloss: 0.185291
Epoch 60, 60/100, training mseloss: 0.169218, testing mseloss: 0.191685
Epoch 61, 61/100, training mseloss: 0.169477, testing mseloss: 0.182557
Epoch 62, 62/100, training mseloss: 0.168397, testing mseloss: 0.172486
Epoch 63, 63/100, training mseloss: 0.167853, testing mseloss: 0.177031
Epoch 64, 64/100, training mseloss: 0.167379, testing mseloss: 0.183901
Epoch 65, 65/100, training mseloss: 0.167024, testing mseloss: 0.178499
Epoch 66, 66/100, training mseloss: 0.166541, testing mseloss: 0.184364
Epoch 67, 67/100, training mseloss: 0.166109, testing mseloss: 0.186502
Epoch 68, 68/100, training mseloss: 0.165685, testing mseloss: 0.178412
Epoch 69, 69/100, training mseloss: 0.165235, testing mseloss: 0.168424
Epoch 70, 70/100, training mseloss: 0.164868, testing mseloss: 0.178120
Epoch 71, 71/100, training mseloss: 0.164488, testing mseloss: 0.177345
Epoch 72, 72/100, training mseloss: 0.164198, testing mseloss: 0.177333
Epoch 73, 73/100, training mseloss: 0.163784, testing mseloss: 0.176825
Epoch 74, 74/100, training mseloss: 0.163420, testing mseloss: 0.181005
Epoch 75, 75/100, training mseloss: 0.163203, testing mseloss: 0.177670
Epoch 76, 76/100, training mseloss: 0.162754, testing mseloss: 0.166122
Epoch 77, 77/100, training mseloss: 0.162485, testing mseloss: 0.177244
Epoch 78, 78/100, training mseloss: 0.162063, testing mseloss: 0.172170
Epoch 79, 79/100, training mseloss: 0.161762, testing mseloss: 0.170248
Epoch 80, 80/100, training mseloss: 0.161432, testing mseloss: 0.170340
Epoch 81, 81/100, training mseloss: 0.161087, testing mseloss: 0.174334
Epoch 82, 82/100, training mseloss: 0.160880, testing mseloss: 0.171467
Epoch 83, 83/100, training mseloss: 0.160451, testing mseloss: 0.166193
Epoch 84, 84/100, training mseloss: 0.160175, testing mseloss: 0.170906
Epoch 85, 85/100, training mseloss: 0.159823, testing mseloss: 0.169389
Epoch 86, 86/100, training mseloss: 0.159538, testing mseloss: 0.165117
Epoch 87, 87/100, training mseloss: 0.159207, testing mseloss: 0.170623
Epoch 88, 88/100, training mseloss: 0.158970, testing mseloss: 0.169152
Epoch 89, 89/100, training mseloss: 0.158766, testing mseloss: 0.172560
Epoch 90, 90/100, training mseloss: 0.158458, testing mseloss: 0.167113
Epoch 91, 91/100, training mseloss: 0.158124, testing mseloss: 0.170533
Epoch 92, 92/100, training mseloss: 0.157771, testing mseloss: 0.167658
Epoch 93, 93/100, training mseloss: 0.157453, testing mseloss: 0.163542
Epoch 94, 94/100, training mseloss: 0.170899, testing mseloss: 0.181840
Epoch 95, 95/100, training mseloss: 0.165556, testing mseloss: 0.189070
Epoch 96, 96/100, training mseloss: 0.161224, testing mseloss: 0.164225
Epoch 97, 97/100, training mseloss: 0.159345, testing mseloss: 0.164547
Epoch 98, 98/100, training mseloss: 0.158414, testing mseloss: 0.177043
Epoch 99, 99/100, training mseloss: 0.157855, testing mseloss: 0.173016
Epoch 100, 100/100, training mseloss: 0.157295, testing mseloss: 0.162513
Model training complete
